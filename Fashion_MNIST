Improving MNIST to 99.8% accuracy or more using only a single convolutional layer and a single MaxPooling 2D.
Stopping training once the accuracy goes above this amount. 
Less than 20 epochs.
When 99.8% accuracy has been hit, print out the string "Reached 99.8% accuracy so cancelling training!"



import tensorflow as tf


class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('acc')>0.998):
      print("\nReached 99.8% accuracy so cancelling training!")
      self.model.stop_training = True

callbacks = myCallback()



mnist = tf.keras.datasets.mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()


training_images=training_images.reshape(60000, 28, 28, 1)
training_images=training_images / 255.0
test_images = test_images.reshape(10000, 28, 28, 1)
test_images=test_images/255.0


model = tf.keras.models.Sequential([
   
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
    
])


model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])





OUTPUT





Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Epoch 1/10
60000/60000 [==============================] - 52s 869us/sample - loss: 0.1483 - acc: 0.9568
Epoch 2/10
60000/60000 [==============================] - 52s 867us/sample - loss: 0.0500 - acc: 0.9847
Epoch 3/10
60000/60000 [==============================] - 52s 871us/sample - loss: 0.0317 - acc: 0.9904
Epoch 4/10
60000/60000 [==============================] - 53s 877us/sample - loss: 0.0205 - acc: 0.9938
Epoch 5/10
60000/60000 [==============================] - 52s 863us/sample - loss: 0.0146 - acc: 0.9954
Epoch 6/10
60000/60000 [==============================] - 52s 860us/sample - loss: 0.0092 - acc: 0.9969
Epoch 7/10
60000/60000 [==============================] - 52s 861us/sample - loss: 0.0084 - acc: 0.9974
Epoch 8/10
60000/60000 [==============================] - 52s 859us/sample - loss: 0.0070 - acc: 0.9977
Epoch 9/10
59936/60000 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9988
Reached 99.8% accuracy so cancelling training!
60000/60000 [==============================] - 52s 865us/sample - loss: 0.0042 - acc: 0.9988
<tensorflow.python.keras.callbacks.History at 0x7f73a41bddd8>
